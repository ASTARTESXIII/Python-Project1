import logging
import requests
import csv
import os
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO)

TOKEN = "7555084230:AAHUDNfvjGduPeULzaNSWV3swoDB3Jh6HRc"
MAX_VACANCIES = 100  # –ú–∞–∫—Å–∏–º—É–º 100 –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
VACANCIES_FILE = "vacancies.csv"
ANALYSIS_FILE = "analysis.csv"
global_nowVac = ""
offset_loadmore = 0
search_data = {}

def write_vacancies_to_csv(vacancies):
    with open(VACANCIES_FILE, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=['name', '–ö–æ–º–ø–∞–Ω–∏—è', '–ó–∞—Ä–ø–ª–∞—Ç–∞', '–°—Å—ã–ª–∫–∞', '–ê–¥—Ä–µ—Å', '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è'])
        writer.writeheader()
        writer.writerows(vacancies)

def write_analysis_to_csv(analysis):
    with open(ANALYSIS_FILE, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π', '–°—Ä–µ–¥–Ω—è—è –∑–ø', '–ú–∏–Ω –∑–ø', '–ú–∞–∫—Å –∑–ø', '–ß–∞—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'])
        writer.writeheader()
        writer.writerows(analysis)

def fetch_vacancies(query, offset=0):
    url = 'https://api.hh.ru/vacancies'
    global offset_loadmore
    offset_loadmore += 11
    all_vacancies = []
    per_page = offset_loadmore
    params = {'text': query, 'area': 113, 'page': offset, 'per_page': per_page}
    response = requests.get(url, params=params)
    
    if response.status_code != 200:
        return []
    
    vacancies = response.json().get('items', [])
    for vacancy in vacancies:
        name = vacancy.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
        employer_name = vacancy.get('employer', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
        salary = vacancy.get('salary', {})
        salary_info = "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
        if salary:
            from_salary = salary.get('from')
            to_salary = salary.get('to')
            if from_salary and to_salary:
                salary_info = f"–æ—Ç {from_salary} –¥–æ {to_salary} RUB"
            elif from_salary:
                salary_info = f"–æ—Ç {from_salary} RUB"
            elif to_salary:
                salary_info = f"–¥–æ {to_salary} RUB"
        address = vacancy.get('address', {}).get('raw', '–£–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞') if vacancy.get('address') else '–ù–µ —É–∫–∞–∑–∞–Ω'
        requirements = vacancy.get('snippet', {}).get('requirement', '–ù–µ —É–∫–∞–∑–∞–Ω—ã')
        all_vacancies.append({
            'name': name,
            '–ö–æ–º–ø–∞–Ω–∏—è': employer_name,
            '–ó–∞—Ä–ø–ª–∞—Ç–∞': salary_info,
            '–°—Å—ã–ª–∫–∞': vacancy.get('alternate_url', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
            '–ê–¥—Ä–µ—Å': address,
            '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è': requirements})

    return all_vacancies

def analyze_salaries(vacancies):
    salaries = []
    for vacancy in vacancies:
        salary_str = vacancy['–ó–∞—Ä–ø–ª–∞—Ç–∞']
        
        if '–æ—Ç' in salary_str and '–¥–æ' in salary_str:
            try:
                salary_parts = salary_str.split()
                from_salary = int(salary_parts[1]) if len(salary_parts) > 1 else None
                to_salary = int(salary_parts[3]) if len(salary_parts) > 3 else None
                if from_salary:
                    salaries.append(from_salary)
                if to_salary:
                    salaries.append(to_salary)
            except ValueError:
                continue 
        elif '–æ—Ç' in salary_str:
            try:
                from_salary = int(salary_str.split()[1])
                salaries.append(from_salary)
            except ValueError:
                continue
        elif '–¥–æ' in salary_str:
            try:
                to_salary = int(salary_str.split()[3]) if len(salary_str.split()) > 3 else None
                if to_salary:
                    salaries.append(to_salary)
            except ValueError:
                continue
    
    if salaries:
        avg_salary = sum(salaries) // len(salaries)
        min_salary = min(salaries)
        max_salary = max(salaries)

        return {
            'avg_salary': avg_salary,
            'min_salary': min_salary,
            'max_salary': max_salary,}
    return {
        'avg_salary': '–Ω–µ —É–∫–∞–∑–∞–Ω–∞',
        'min_salary': '–Ω–µ —É–∫–∞–∑–∞–Ω–∞',
        'max_salary': '–Ω–µ —É–∫–∞–∑–∞–Ω–∞',}

def recommend_skills(vacancies):
    all_requirements = ' '.join([vacancy['–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è'] if vacancy['–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è'] else '' for vacancy in vacancies]).lower()
    skill_keywords = ['python', 'sql', 'linux', 'java', 'c++', 'networking', 'security', 'cloud', 'aws', 'data']
    recommended_skills = [skill for skill in skill_keywords if skill in all_requirements]

    if recommended_skills:
        return f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞–≤—ã–∫–∏: {', '.join(recommended_skills)}"
    return "–ù–µ—Ç —è–≤–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –Ω–∞–≤—ã–∫–∞–º."

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    
    global offset_loadmore
    offset_loadmore = 0    
    if os.path.exists(ANALYSIS_FILE):
        os.remove(ANALYSIS_FILE)
    if os.path.exists(VACANCIES_FILE):
        os.remove(VACANCIES_FILE)
    
    context.user_data.clear()
    context.user_data['search_in_progress'] = False
    context.user_data['waiting_for_number'] = False
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é, –∫–æ—Ç–æ—Ä—É—é –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥–æ–±—Ä–∞—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä: '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'.")

async def handle_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text.strip()
    global global_nowVac
    global_nowVac = query
    if context.user_data.get('search_in_progress', False):
        await update.message.reply_text("–í—ã —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–æ–∏—Å–∫–∞. –ó–∞–≤–µ—Ä—à–∏—Ç–µ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å.")
        return

    context.user_data['search_in_progress'] = True
    await update.message.reply_text("–í –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –ø–æ–ª—É—á–∞—é –≤–∞–∫–∞–Ω—Å–∏–∏, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ...")
    vacancies = fetch_vacancies(query)
    
    if not vacancies:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")
        context.user_data['search_in_progress'] = False
        return

    write_vacancies_to_csv(vacancies)
    salary_analysis = analyze_salaries(vacancies)
    skill_recommendations = recommend_skills(vacancies)
    analysis_data = [{
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π': len(vacancies),
        '–°—Ä–µ–¥–Ω—è—è –∑–ø': salary_analysis.get('avg_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
        '–ú–∏–Ω –∑–ø': salary_analysis.get('min_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
        '–ú–∞–∫—Å –∑–ø': salary_analysis.get('max_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
        '–ß–∞—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è': ' '.join(skill_recommendations.split()[2:]),
        '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': skill_recommendations}]
    
    write_analysis_to_csv(analysis_data)
    for vacancy in vacancies[:11]:
        try:
            await update.message.reply_text(
                f"üîπ {vacancy['name']}\n"
                f"üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {vacancy['–ö–æ–º–ø–∞–Ω–∏—è']}\n"
                f"üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {vacancy['–ó–∞—Ä–ø–ª–∞—Ç–∞']}\n"
                f"üìç –ê–¥—Ä–µ—Å: {vacancy['–ê–¥—Ä–µ—Å']}\n"
                f"üìë –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {vacancy['–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è']}\n"
                f"üîó –°—Å—ã–ª–∫–∞: <{vacancy['–°—Å—ã–ª–∫–∞']}>",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º < > –¥–ª—è —Å—Å—ã–ª–∫–∏
                parse_mode="Markdown", disable_web_page_preview=True
            )
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")

async def analyze(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if os.path.exists(ANALYSIS_FILE):
        with open(ANALYSIS_FILE, mode='r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            analysis_data = list(reader)
            
            if analysis_data:
                analysis = analysis_data[0]
                await update.message.reply_text(
                    f"üìä –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π:\n"
                    f"üîπ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π: {analysis['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π']}\n"
                    f"üí∞ –°—Ä–µ–¥–Ω—è—è –∑–ø: {analysis['–°—Ä–µ–¥–Ω—è—è –∑–ø']}\n"
                    f"üìâ –ú–∏–Ω –∑–ø: {analysis['–ú–∏–Ω –∑–ø']}\n"
                    f"üìà –ú–∞–∫—Å –∑–ø: {analysis['–ú–∞–∫—Å –∑–ø']}\n"
                    f"üí° –ß–∞—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è: {analysis['–ß–∞—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è']}\n"
                    f"üîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {analysis['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏']}")
            else:
                await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
    else:
        await update.message.reply_text("–§–∞–π–ª –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

async def load_more(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global global_nowVac
    query = str(global_nowVac)
    offset = context.user_data.get('offset', 0)
    new_vacancies = fetch_vacancies(query, offset=offset)
    
    if not new_vacancies:
        await update.message.reply_text("–ù–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    try:
        with open(VACANCIES_FILE, mode='r', encoding='utf-8') as file:
            existing_vacancies = list(csv.DictReader(file))
    except FileNotFoundError:
        existing_vacancies = []

    unique_vacancies = [vacancy for vacancy in new_vacancies if vacancy not in existing_vacancies]    
    if unique_vacancies:
        existing_vacancies.extend(unique_vacancies)
        write_vacancies_to_csv(existing_vacancies)
        salary_analysis = analyze_salaries(existing_vacancies)
        skill_recommendations = recommend_skills(existing_vacancies)
        analysis_data = [{
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π': len(existing_vacancies),
            '–°—Ä–µ–¥–Ω—è—è –∑–ø': salary_analysis.get('avg_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
            '–ú–∏–Ω –∑–ø': salary_analysis.get('min_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
            '–ú–∞–∫—Å –∑–ø': salary_analysis.get('max_salary', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
            '–ß–∞—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è': ' '.join(skill_recommendations.split()[2:]),
            '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': skill_recommendations}]
        write_analysis_to_csv(analysis_data)
        for vacancy in unique_vacancies:
            try:
                await update.message.reply_text(
                    f"üîπ {vacancy['name']}\n"
                    f"üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {vacancy['–ö–æ–º–ø–∞–Ω–∏—è']}\n"
                    f"üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {vacancy['–ó–∞—Ä–ø–ª–∞—Ç–∞']}\n"
                    f"üìç –ê–¥—Ä–µ—Å: {vacancy['–ê–¥—Ä–µ—Å']}\n"
                    f"üìë –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {vacancy['–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è']}\n"
                    f"üîó –°—Å—ã–ª–∫–∞: {vacancy['–°—Å—ã–ª–∫–∞']}",
                    parse_mode="Markdown", disable_web_page_preview=True)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
        context.user_data['offset'] = offset + 1
    else:
        await update.message.reply_text("–ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.")

async def new_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    
    global offset_loadmore
    offset_loadmore = 0 
    if os.path.exists(VACANCIES_FILE):
        os.remove(VACANCIES_FILE)
    if os.path.exists(ANALYSIS_FILE):
        os.remove(ANALYSIS_FILE)
    
    context.user_data.clear()
    context.user_data['search_in_progress'] = False
    context.user_data['waiting_for_number'] = False
    context.user_data['vacancies'] = []
    await update.message.reply_text("–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥–æ–±—Ä–∞—Ç—å.")

def main():
    application = ApplicationBuilder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("analyze", analyze))
    application.add_handler(CommandHandler("load_more", load_more))
    application.add_handler(CommandHandler("new_search", new_search))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_query))

    application.run_polling()

if __name__ == '__main__':
    main()